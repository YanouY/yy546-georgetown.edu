{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Yang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('wordnet')\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text, stemmer):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    \n",
    "def preprocess(text, stemmer):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    result = []\n",
    "    for token in word_tokenize(text.lower()):\n",
    "        eng_stopwords = set(stopwords.words('english'))\n",
    "        if token not in eng_stopwords and len(token) >= 3:\n",
    "            result.append(lemmatize_stemming(token, stemmer))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_model(i, bow_corpus, dictionary):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(bow_corpus, \n",
    "                                            num_topics=i,\n",
    "                                            id2word=dictionary, \n",
    "                                            passes=2)\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_plot():\n",
    "    scores = []\n",
    "    for i in range(1,20):\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(bow_corpus, \n",
    "                                                num_topics=i, \n",
    "                                                id2word=dictionary, \n",
    "                                                passes=2)\n",
    "        cm = CoherenceModel(model=lda_model,texts = texts, corpus=bow_corpus, coherence='c_v')\n",
    "        coherence = cm.get_coherence()\n",
    "        scores.append(coherence)\n",
    "    limit=20; start=1; step=1;\n",
    "    x = range(start, limit, step)\n",
    "    plt.plot(x, scores)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    plt.ylabel(\"Coherence score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(lda_model, bow_corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(lda_model[bow_corpus]):\n",
    "        row = row_list[0] if lda_model.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = lda_model.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_keyword(final_result):\n",
    "    con = final_result.groupby(\"Dominant_Topic\")\n",
    "    new = pd.DataFrame()\n",
    "    for i, grp in con:\n",
    "        new = pd.concat([new, grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                                axis=0)\n",
    "    new.reset_index(drop=True, inplace=True)\n",
    "    new.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "    new = new.drop(['Topic_Perc_Contrib'], axis=1)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"review_data_cleaned.csv\")\n",
    "text = data['review']\n",
    "stemmer = PorterStemmer()\n",
    "result = []\n",
    "for i in range(len(text)):\n",
    "    result.append(preprocess(text[i], stemmer))\n",
    "dictionary = gensim.corpora.Dictionary(result)\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_plot() # From the graph, we can see 10 is the best optimal number of topics\n",
    "lda_model1 = lda_model(10, bow_corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.031*\"museum\" + 0.017*\"place\" + 0.016*\"ever\" + 0.016*\"visit\" + 0.015*\"park\" + 0.014*\"best\" + 0.012*\"get\" + 0.011*\"one\" + 0.011*\"experi\" + 0.011*\"like\"\n",
      "Topic: 1 \n",
      "Words: 0.029*\"venu\" + 0.018*\"great\" + 0.016*\"see\" + 0.015*\"time\" + 0.014*\"place\" + 0.013*\"concert\" + 0.012*\"first\" + 0.012*\"go\" + 0.011*\"music\" + 0.011*\"seat\"\n",
      "Topic: 2 \n",
      "Words: 0.026*\"instal\" + 0.026*\"work\" + 0.023*\"home\" + 0.022*\"servic\" + 0.019*\"great\" + 0.015*\"system\" + 0.015*\"job\" + 0.013*\"profession\" + 0.012*\"use\" + 0.011*\"time\"\n",
      "Topic: 3 \n",
      "Words: 0.046*\"show\" + 0.023*\"see\" + 0.021*\"perform\" + 0.020*\"great\" + 0.018*\"theatr\" + 0.018*\"theater\" + 0.017*\"amaz\" + 0.016*\"product\" + 0.013*\"play\" + 0.012*\"talent\"\n",
      "Topic: 4 \n",
      "Words: 0.033*\"place\" + 0.026*\"movi\" + 0.025*\"theater\" + 0.023*\"great\" + 0.018*\"love\" + 0.017*\"nice\" + 0.015*\"food\" + 0.014*\"good\" + 0.014*\"come\" + 0.011*\"like\"\n",
      "Topic: 5 \n",
      "Words: 0.022*\"seat\" + 0.021*\"theater\" + 0.015*\"great\" + 0.015*\"theatr\" + 0.011*\"drink\" + 0.011*\"get\" + 0.010*\"bad\" + 0.009*\"see\" + 0.009*\"come\" + 0.009*\"love\"\n",
      "Topic: 6 \n",
      "Words: 0.025*\"theater\" + 0.015*\"art\" + 0.014*\"see\" + 0.012*\"star\" + 0.011*\"first\" + 0.010*\"time\" + 0.010*\"great\" + 0.009*\"broadway\" + 0.009*\"show\" + 0.009*\"theatr\"\n",
      "Topic: 7 \n",
      "Words: 0.029*\"year\" + 0.028*\"class\" + 0.023*\"take\" + 0.020*\"danc\" + 0.016*\"daughter\" + 0.012*\"studio\" + 0.012*\"love\" + 0.010*\"chicago\" + 0.010*\"teacher\" + 0.010*\"school\"\n",
      "Topic: 8 \n",
      "Words: 0.038*\"show\" + 0.026*\"night\" + 0.025*\"go\" + 0.021*\"time\" + 0.020*\"last\" + 0.020*\"ticket\" + 0.017*\"see\" + 0.016*\"get\" + 0.014*\"first\" + 0.014*\"year\"\n",
      "Topic: 9 \n",
      "Words: 0.019*\"ticket\" + 0.013*\"one\" + 0.012*\"show\" + 0.012*\"park\" + 0.011*\"locat\" + 0.010*\"event\" + 0.009*\"shop\" + 0.008*\"come\" + 0.008*\"mall\" + 0.008*\"time\"\n"
     ]
    }
   ],
   "source": [
    "# print 10 topics\n",
    "for idx, topic in lda_model1.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3891</td>\n",
       "      <td>venu, great, see, time, place, concert, first,...</td>\n",
       "      <td>Clean and big spaces! Chairs are super comfy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.6696</td>\n",
       "      <td>show, night, go, time, last, ticket, see, get,...</td>\n",
       "      <td>My favorite theater severely disappointed me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5384</td>\n",
       "      <td>place, movi, theater, great, love, nice, food,...</td>\n",
       "      <td>Cinemark has made a ton of improvements since ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3492</td>\n",
       "      <td>museum, place, ever, visit, park, best, get, o...</td>\n",
       "      <td>it's not the best experience you'll ever have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6198</td>\n",
       "      <td>place, movi, theater, great, love, nice, food,...</td>\n",
       "      <td>I'm updating my review to two stars.  This is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dominant_Topic  Perc_Contribution  \\\n",
       "0             1.0             0.3891   \n",
       "1             8.0             0.6696   \n",
       "2             4.0             0.5384   \n",
       "3             0.0             0.3492   \n",
       "4             4.0             0.6198   \n",
       "\n",
       "                                      Topic_Keywords  \\\n",
       "0  venu, great, see, time, place, concert, first,...   \n",
       "1  show, night, go, time, last, ticket, see, get,...   \n",
       "2  place, movi, theater, great, love, nice, food,...   \n",
       "3  museum, place, ever, visit, park, best, get, o...   \n",
       "4  place, movi, theater, great, love, nice, food,...   \n",
       "\n",
       "                                              review  \n",
       "0  Clean and big spaces! Chairs are super comfy a...  \n",
       "1  My favorite theater severely disappointed me t...  \n",
       "2  Cinemark has made a ton of improvements since ...  \n",
       "3  it's not the best experience you'll ever have ...  \n",
       "4  I'm updating my review to two stars.  This is ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate each document sentence dominant topic and contribution\n",
    "final_result = format_topics_sentences(lda_model1,bow_corpus, text )\n",
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>museum, place, ever, visit, park, best, get, o...</td>\n",
       "      <td>A fine little museum with super nice people wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>venu, great, see, time, place, concert, first,...</td>\n",
       "      <td>Best place in town to see and hear a good even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>instal, work, home, servic, great, system, job...</td>\n",
       "      <td>Kevin and his crew were awesome !!!!!\\nGreat C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>show, see, perform, great, theatr, theater, am...</td>\n",
       "      <td>I found the theatre quaint, personal and uniqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>place, movi, theater, great, love, nice, food,...</td>\n",
       "      <td>Beautiful place to spend time with family and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num                                           Keywords  \\\n",
       "0        0.0  museum, place, ever, visit, park, best, get, o...   \n",
       "1        1.0  venu, great, see, time, place, concert, first,...   \n",
       "2        2.0  instal, work, home, servic, great, system, job...   \n",
       "3        3.0  show, see, perform, great, theatr, theater, am...   \n",
       "4        4.0  place, movi, theater, great, love, nice, food,...   \n",
       "\n",
       "                                                Text  \n",
       "0  A fine little museum with super nice people wo...  \n",
       "1  Best place in town to see and hear a good even...  \n",
       "2  Kevin and his crew were awesome !!!!!\\nGreat C...  \n",
       "3  I found the theatre quaint, personal and uniqu...  \n",
       "4  Beautiful place to spend time with family and ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most representative sentence to the topics\n",
    "sentence_keyword1 = sentence_keyword(final_result)\n",
    "sentence_keyword1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
